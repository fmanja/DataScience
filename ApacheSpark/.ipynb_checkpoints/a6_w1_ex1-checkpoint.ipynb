{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>F. Manja - Exercise 1 Submission</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to exercise one of “Apache Spark for Scalable Machine Learning on BigData”. In this exercise you’ll apply the basics of functional and parallel programming. \n",
    "\n",
    "Let’s start with a simple example. Let’s consider you have a list of integers.\n",
    "\n",
    "Let’s find out what the size of this list is.\n",
    "\n",
    "Note that we already provide an RDD object, so please have a look at the RDD API in order to find out what function to use:\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD\n",
    "\n",
    "The following link contains additional documentation:\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Apache Spark Setup</h2>\n",
    "<a href=\"https://www.tutorialkart.com/apache-spark/how-to-install-spark-on-mac-os/\">Apache Spark (Mac install)</a><br>\n",
    "Don't forget to start the Spark Shell with this command> spark-shell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(Optional) </h3>\n",
    "Install findspark and pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /anaconda3/lib/python3.7/site-packages (1.3.0)\n",
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 70kB/s s eta 0:00:01   |████▏                           | 27.9MB 6.7MB/s eta 0:00:29     |███████▊                        | 52.3MB 59.3MB/s eta 0:00:03     |████████                        | 53.7MB 59.3MB/s eta 0:00:03     |████████████████                | 108.3MB 13.3MB/s eta 0:00:09     |████████████████████▊           | 139.5MB 45.9MB/s eta 0:00:02     |█████████████████████▌          | 144.9MB 45.9MB/s eta 0:00:02     |███████████████████████████▏    | 182.9MB 20.4MB/s eta 0:00:02     |███████████████████████████▍    | 184.7MB 20.4MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 29.5MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/frankmanja/Library/Caches/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
     ]
    }
   ],
   "source": [
    "# Uncomment lines below if needed\n",
    "#! pip install findspark \n",
    "#! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"MyFirstApp\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# please replace $$ with the correct characters\n",
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see \"100\" as answer. Now we want to know the sum of all elements. Please again, have a look at the API documentation and complete the code below in order to get the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get \"4950\" as answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
